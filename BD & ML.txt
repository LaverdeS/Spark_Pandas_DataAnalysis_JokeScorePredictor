https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/

**https://spark.apache.org/docs/2.3.0/sql-programming-guide.html#datasets-and-dataframes
https://spark.apache.org/docs/2.3.0/api/python/pyspark.html#module-pyspark

http://www.bmc.com/blogs/sgd-linear-regression-example-apache-spark/
https://www.lucasallen.io/spark-dataframes-mllib-tutorial/

https://www.uni-weimar.de/fileadmin/user/fak/medien/professuren/Webis/teaching/ss18/big-data-seminar/bigdata-ss18-intro-frame.pdf CHECKED
http://community.wolfram.com/groups/-/m/t/1145469 CHECKED
https://www.wolframcloud.com/objects/agriffin/HumorDetector CHECKED
http://www.coli.uni-saarland.de/courses/cacl10/slides/Humor_Kaeshammer.pdf CHECKED (slides para mi presentacion. Con links, heuristics + stylistic features)
http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp05b.pdf CHECKED (PDF del anterior)
https://www.cs.ox.ac.uk/files/244/mihalcea.cicling07.pdf CHECKED (Apoyo al anterior)
https://github.com/pln-fing-udelar/pghumor CHECKED (TESIS classifier in Spanish...)
https://pdfs.semanticscholar.org/9b13/5cab89155147f56559ddcc10b404c44f5db9.pdf CHECKED (pdf de la tesis)
https://web.stanford.edu/~jurafsky/slp3/6.pdf CHECKED (naive bayes sentiment (+ or -) classifier
https://github.com/wsilva/humor-classifier-with-naive-bayes/blob/master/python/NaiveBayesWordClassifier.py CHECKED (stopwords and example of Nayve bayes in python...)

https://www.google.de/search?q=Learning+to+Laugh+(Automatically)%3A+Computational+Models+for+Humor+Recognition.&oq=Learning+to+Laugh+(Automatically)%3A+Computational+Models+for+Humor+Recognition.&aqs=chrome..69i57.539j0j4&sourceid=chrome&ie=UTF-8
https://www.cs.cmu.edu/~diyiy/docs/emnlp_yang_16.pdf (no python or nayve bayes etc related)
https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/workshops/Miller_ISSSHS_2016.pdf
https://en.wikipedia.org/wiki/Computational_humor
https://www.google.de/search?q=Kiddon+%26+Brun%27s+TWSS+system&oq=Kiddon+%26+Brun%27s+TWSS+system&aqs=chrome..69i57j0.1121j0j7&sourceid=chrome&ie=UTF-8
https://www.google.de/search?ei=itAHW8KvMovb6QSXjK-ACg&q=how+to+open+json+file&oq=how+to+open+json+file&gs_l=psy-ab.3..0i67k1j0l2j0i20i263k1j0l6.14293.17689.0.17913.13.12.0.0.0.0.198.1338.0j9.9.0....0...1c.1.64.psy-ab..6.7.966...0i7i10i30k1j0i10k1j0i8i7i30k1j0i8i7i10i30k1j0i13k1j0i8i13i30k1j0i13i30k1j0i10i30k1j0i8i30k1.0.gKw159q6dFY#kpvalbx=1
https://www.google.de/search?q=spark+mllib+classification+example&oq=spark+mllib+class&aqs=chrome.3.35i39j69i60j69i57j0l3.14548j0j7&sourceid=chrome&ie=UTF-8
https://mapr.com/blog/classifying-customers-mllib-and-spark/

LONG TALKS-JOKES PROJECT technic facts:
https://www.programmableweb.com/api/reddit
https://github.com/reddit-archive/reddit/wiki/JSON
https://spark.apache.org/docs/2.3.0/quick-start.html

https://www.google.de/search?ei=b4kNW9yUBujP6AS0pp6wAQ&q=create+labeledpoint+from+dataframe+pyspark&oq=creating+a+labeledpoint+from+data+frame&gs_l=psy-ab.3.1.0i22i30k1j0i22i10i30k1.30647.41757.0.43842.31.25.3.1.2.0.259.3520.0j14j5.19.0....0...1c.1.64.psy-ab..8.22.3329...0j35i39k1j0i67k1j0i20i263k1j0i13k1j33i22i29i30k1.0.W_9eSgG1N9Q
https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#module-pyspark.mllib.regression
https://www.coursera.org/payments/checkout?cartId=21207247

spark
sc

rdd1 = sc.parallelize(range(1,100))
rdd1.map(lambda x: x*x).collect
rdd1.map(lambda x: x*x).reduce(lamda a, b: a+b)

%matplotlib inline (to create the graph in notebook)
import matplotlib.pyplot as plt
plt.plot([0,1,2],[1,2,5])

plt.plot(rdd1.collect(), rdd1.map(lambda x: x**2).collect

celltype markdown is for comments links and things like that (pretty useful to keep things in the same place)

import json
with open("reddit.json", "r") as read_file:
    data = json.load(read_file)

check collect and collectAsMap (interesting)

************ 04.06.2018 ***********
check udf
check df.withColumn

read corpus as a json to correct the features

https://www.uni-weimar.de/fileadmin/user/fak/medien/professuren/Webis/teaching/ss18/big-data-seminar/hadoop-tutorial-frame.pdf
wido1873 : ri4aph9cu7Feev
https://webis17.medien.uni-weimar.de:8000

https://qwermovies.com/watch-tvseries/spartacus-online/spartacus-season-1-online-free-hd-streaming-qwermovies
https://123movies.fun/film/spartacus-blood-and-sand-season-1-6436/watching.html?ep=368806
https://www1.1movies.se/series/spartacus-blood-and-sand-season-1/26247/33706-watch-online-free.html

https://www2.1movies.se/series/spartacus-blood-and-sand-season-2/25556/22139-watch-online-free.html

**********************************************************************************
TO FILTER I HAVE TWO OPTIONS

first with sql SELECT https://spark.apache.org/docs/latest/sql-programming-guide.html (and search for parquet) 
HERE I CAN ALSO FIND HOW TO MERGE AND CREATE A NEW FEATURE IN THE FILE:) Bucketing, Sorting and Partitioning, write and save, Schema merging
https://spark.apache.org/docs/latest/sql-programming-guide.html (Check data sources)

or looking in the documentation and just typing df.select

NORMALIZE THE SCORE TO SCORE JOKES AND UNJOKES

Content, knock knock, walks into a bar, why the chicken, ho do you call, what did a ... say. international people, exclamation marks.

swear words
adult slang
nationalities
animals
superheroes/villans
disneys characters
high score joke words
cartoons
movie characters

IMPROVEMENT
make a better and clean dictionary
clean the database from strange values
add more semantic features
run other regression with another distribution (not linear but gaussian)
run other algortihm like decision trees and SVM
combine them all and test a lot
try measuring other types of error (not compared with the average but the more typical score perhaps)
analize for deeply the high score database